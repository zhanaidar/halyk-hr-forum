{
  "profile": "Data Scientist",
  "specialization": "Data Science",
  "file_name": "Data_Scientist",
  "competencies": [
    {
      "competency": "Статистика и теория вероятностей",
      "type": "CORE",
      "importance": 90,
      "themes": [
        {
          "theme": "Проверка статистических гипотез и A/B тестирование",
          "questions": [
            {
              "level": "Junior",
              "question": "Что такое p-value в контексте A/B теста и какой порог обычно используется для определения статистической значимости?",
              "correct_answer": "Вероятность получить результат при истинной нулевой гипотезе, порог 0.05"
            },
            {
              "level": "Middle",
              "question": "В банке тестируют новый интерфейс мобильного приложения. Какой статистический тест использовать для сравнения конверсии в оформление кредита между группами, если размер выборки 5000 пользователей в каждой группе?",
              "correct_answer": "Z-тест для разности двух пропорций или хи-квадрат тест"
            },
            {
              "level": "Senior",
              "question": "Телеком запускает A/B тест новой тарифной модели на 2% пользователей. Как спроектировать систему мониторинга для раннего обнаружения негативного эффекта, учитывая проблему множественных сравнений при ежедневной проверке метрик?",
              "correct_answer": "Sequential testing с adjusted alpha boundaries или Bayesian monitoring с предустановленными stopping rules"
            }
          ]
        },
        {
          "theme": "Распределения вероятностей и их применение в машинном обучении",
          "questions": [
            {
              "level": "Junior",
              "question": "Какое распределение вероятностей используется для моделирования бинарных исходов, например, дефолт/не дефолт клиента банка?",
              "correct_answer": "Распределение Бернулли"
            },
            {
              "level": "Middle",
              "question": "Почему для моделирования времени между звонками в колл-центре телеком-оператора используют экспоненциальное распределение вместо нормального?",
              "correct_answer": "Экспоненциальное распределение моделирует время между независимыми событиями и определено только для положительных значений"
            },
            {
              "level": "Senior",
              "question": "Как выбор prior распределения в байесовской модели кредитного скоринга влияет на устойчивость предсказаний при дрейфе данных и какое семейство распределений предпочтительнее для small data сценариев?",
              "correct_answer": "Информативный prior со слабой регуляризацией стабилизирует оценки при дрейфе; conjugate prior семейства обеспечивают аналитические решения для малых выборок"
            }
          ]
        },
        {
          "theme": "Корреляционный и регрессионный анализ данных",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой коэффициент корреляции указывает на сильную положительную линейную связь между суммой кредита и доходом клиента банка?",
              "correct_answer": "Коэффициент Пирсона близкий к +1"
            },
            {
              "level": "Middle",
              "question": "В чем ключевое отличие Ridge от Lasso регрессии при прогнозировании оттока абонентов телеком-оператора с 50+ признаками?",
              "correct_answer": "Lasso обнуляет коэффициенты, Ridge уменьшает, не обнуляя"
            },
            {
              "level": "Senior",
              "question": "Почему при построении модели скоринга для необанкинга следует использовать квантильную регрессию вместо OLS при наличии выбросов в данных о доходах?",
              "correct_answer": "Квантильная регрессия робастна к выбросам и моделирует условные квантили распределения"
            }
          ]
        },
        {
          "theme": "Байесовская статистика и условные вероятности",
          "questions": [
            {
              "level": "Junior",
              "question": "Что показывает теорема Байеса при расчете вероятности мошеннической транзакции после получения сигнала от антифрод-системы?",
              "correct_answer": "Апостериорную вероятность мошенничества с учетом наблюдаемых данных"
            },
            {
              "level": "Middle",
              "question": "В телеком-компании base rate оттока клиентов 2%, модель предсказывает отток с точностью 85%. Почему нельзя использовать только accuracy для оценки модели?",
              "correct_answer": "Несбалансированные классы приводят к высокой accuracy даже при неинформативных предсказаниях"
            },
            {
              "level": "Senior",
              "question": "При построении байесовской модели скоринга в банке, как выбрать между информативными и неинформативными prior-распределениями для параметров кредитного риска в условиях ограниченных исторических данных?",
              "correct_answer": "Использовать слабо-информативные prior на основе экспертных оценок и регуляторных требований"
            }
          ]
        }
      ]
    },
    {
      "competency": "Python для Data Science (pandas, numpy, scikit-learn)",
      "type": "CORE",
      "importance": 90,
      "themes": [
        {
          "theme": "Манипуляция и обработка данных с pandas: индексация, группировка, объединение датафреймов",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой метод pandas используется для объединения двух датафреймов по общему столбцу, аналогично SQL JOIN?",
              "correct_answer": "merge() или pd.merge()"
            },
            {
              "level": "Middle",
              "question": "В чем разница между merge() и concat() при объединении датафреймов с транзакциями клиентов банка из разных филиалов?",
              "correct_answer": "merge объединяет по ключам, concat склеивает по осям без условий"
            },
            {
              "level": "Senior",
              "question": "Почему при группировке 50 млн телеком CDR-записей по абонентам стоит использовать категориальные типы для phone_number перед groupby?",
              "correct_answer": "Снижает потребление памяти и ускоряет группировку за счет целочисленных кодов"
            }
          ]
        },
        {
          "theme": "Векторизация и математические операции с numpy: Broadcasting, линейная алгебра, работа с массивами",
          "questions": [
            {
              "level": "Junior",
              "question": "Что произойдет при сложении numpy массива формы (5, 1) с массивом формы (3,) согласно правилам broadcasting?",
              "correct_answer": "Произойдет ошибка ValueError из-за несовместимости размерностей"
            },
            {
              "level": "Middle",
              "question": "Для расчета корреляционной матрицы клиентских транзакций размером (10000, 50) что эффективнее: np.corrcoef или стандартизация с последующим np.dot, и почему?",
              "correct_answer": "np.dot после стандартизации быстрее за счет оптимизированного BLAS"
            },
            {
              "level": "Senior",
              "question": "При векторизации расчета расстояний между 1 млн клиентов банка (shape 1000000, 128) память переполняется. Как оптимизировать без циклов, сохранив производительность numpy?",
              "correct_answer": "Использовать chunking с np.einsum или broadcasting блоками через np.add.outer"
            }
          ]
        },
        {
          "theme": "Построение и оценка моделей машинного обучения с scikit-learn: Pipeline, кросс-валидация, метрики качества",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой класс scikit-learn используется для объединения препроцессинга и модели в единую последовательность трансформаций?",
              "correct_answer": "Pipeline"
            },
            {
              "level": "Middle",
              "question": "Какую стратегию кросс-валидации следует использовать для временных рядов транзакций клиентов банка, чтобы избежать утечки данных из будущего?",
              "correct_answer": "TimeSeriesSplit, сохраняющий хронологический порядок данных"
            },
            {
              "level": "Senior",
              "question": "Почему в Pipeline для модели скоринга клиентов телекома следует применять fit_transform на train и только transform на validation внутри кросс-валидации?",
              "correct_answer": "Предотвращает data leakage через статистики валидационного сета в обучающий"
            }
          ]
        },
        {
          "theme": "Предобработка данных и feature engineering: обработка пропусков, кодирование категориальных признаков, масштабирование",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой метод pandas используется для заполнения пропущенных значений в DataFrame константой?",
              "correct_answer": "fillna() с указанием значения для заполнения"
            },
            {
              "level": "Middle",
              "question": "В датасете банка есть категориальный признак 'регион' с 50 уникальными значениями и высокой кардинальностью. Какой метод кодирования предпочтительнее: OneHotEncoder или TargetEncoder, и почему?",
              "correct_answer": "TargetEncoder, так как избегает создания 50 признаков и curse of dimensionality"
            },
            {
              "level": "Senior",
              "question": "При построении пайплайна предобработки для скоринговой модели банка вы применяете SimpleImputer и StandardScaler. Почему критически важно fit этих трансформеров только на train выборке, а не на всем датасете?",
              "correct_answer": "Предотвращает data leakage - информация из test попадет в параметры трансформеров"
            }
          ]
        }
      ]
    },
    {
      "competency": "SQL и работа с базами данных",
      "type": "CORE",
      "importance": 85,
      "themes": [
        {
          "theme": "Основы SQL: SELECT-запросы, фильтрация, сортировка и агрегатные функции",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой оператор SQL используется для фильтрации строк по условию в запросе SELECT?",
              "correct_answer": "WHERE"
            },
            {
              "level": "Middle",
              "question": "В чем разница между WHERE и HAVING при работе с агрегатными функциями в запросах к таблице транзакций банка?",
              "correct_answer": "WHERE фильтрует строки до агрегации, HAVING фильтрует результаты после агрегации"
            },
            {
              "level": "Senior",
              "question": "Почему запрос с COUNT(DISTINCT client_id) и GROUP BY на таблице с 500 млн транзакций телеком-оператора выполняется медленно, и как оптимизировать без изменения логики?",
              "correct_answer": "DISTINCT требует сортировки и дедупликации в памяти; решение через индексы, партиционирование или материализованные представления"
            }
          ]
        },
        {
          "theme": "JOIN-операции и подзапросы для объединения данных из множества таблиц",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой тип JOIN вернет все записи из левой таблицы клиентов банка и совпадающие записи из таблицы транзакций?",
              "correct_answer": "LEFT JOIN или LEFT OUTER JOIN"
            },
            {
              "level": "Middle",
              "question": "В чем разница между использованием подзапроса в WHERE и JOIN при объединении таблиц абонентов и их платежей в телеком-системе?",
              "correct_answer": "JOIN возвращает колонки обеих таблиц, подзапрос в WHERE только фильтрует строки основной таблицы"
            },
            {
              "level": "Senior",
              "question": "Почему коррелированный подзапрос для расчета остатков по счетам клиентов может вызвать проблемы производительности и какую архитектуру выбрать вместо него?",
              "correct_answer": "Выполняется для каждой строки основного запроса. Использовать оконные функции или материализованные представления с инкрементальным обновлением"
            }
          ]
        },
        {
          "theme": "Оконные функции (Window Functions) для аналитических вычислений",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой синтаксис используется для создания оконной функции ROW_NUMBER() для нумерации транзакций клиентов банка по дате?",
              "correct_answer": "ROW_NUMBER() OVER (PARTITION BY client_id ORDER BY transaction_date)"
            },
            {
              "level": "Middle",
              "question": "В чем разница между ROWS BETWEEN и RANGE BETWEEN при вычислении скользящего среднего баланса абонентов телеком-оператора за последние 3 месяца?",
              "correct_answer": "ROWS учитывает физические строки, RANGE группирует одинаковые значения ORDER BY"
            },
            {
              "level": "Senior",
              "question": "Почему при расчете процентилей доходов клиентов на миллионах записей следует использовать NTILE вместо комбинации ROW_NUMBER и подзапросов?",
              "correct_answer": "NTILE выполняется за один проход, не требует самосоединения и минимизирует сортировку"
            }
          ]
        },
        {
          "theme": "Оптимизация запросов, индексы и работа с планами выполнения",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой оператор SQL используется для просмотра плана выполнения запроса перед его фактическим исполнением?",
              "correct_answer": "EXPLAIN или EXPLAIN PLAN в зависимости от СУБД"
            },
            {
              "level": "Middle",
              "question": "В таблице транзакций банка (50 млн записей) часто выполняется запрос по номеру карты и дате. Какой тип индекса оптимален и почему?",
              "correct_answer": "Составной индекс (card_number, date) для покрытия обоих условий фильтрации"
            },
            {
              "level": "Senior",
              "question": "В DWH телеком-оператора запрос с JOIN трех больших таблиц (абоненты, тарифы, транзакции) выполняется 40 минут. План показывает Nested Loop. Как оптимизировать архитектурно и на уровне запроса?",
              "correct_answer": "Обновить статистику, добавить индексы на join-ключи, использовать Hash Join через hints, рассмотреть партиционирование и материализованные представления для агрегатов"
            }
          ]
        }
      ]
    },
    {
      "competency": "Построение классических моделей ML",
      "type": "CORE",
      "importance": 90,
      "themes": [
        {
          "theme": "Линейные модели и регуляризация (Linear Regression, Ridge, Lasso, ElasticNet)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой метод sklearn используется для обучения линейной регрессии с L2-регуляризацией?",
              "correct_answer": "Ridge из sklearn.linear_model"
            },
            {
              "level": "Middle",
              "question": "В модели скоринга клиентов банка получили мультиколлинеарность между доходом и суммой депозита. Какую регуляризацию применить и почему?",
              "correct_answer": "Ridge, так как сохраняет все признаки, уменьшая их веса при мультиколлинеарности"
            },
            {
              "level": "Senior",
              "question": "При построении модели прогноза оттока абонентов телеком-оператора с 500 признаками Lasso обнуляет 90% весов. Как оптимизировать pipeline для продакшена?",
              "correct_answer": "Использовать SelectFromModel для удаления нулевых признаков, затем переобучить Ridge на оставшихся"
            }
          ]
        },
        {
          "theme": "Ансамблевые методы и деревья решений (Random Forest, Gradient Boosting, XGBoost, LightGBM)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой гиперпараметр в Random Forest контролирует количество деревьев в ансамбле?",
              "correct_answer": "n_estimators"
            },
            {
              "level": "Middle",
              "question": "Почему LightGBM быстрее XGBoost при обучении на датасете из 5 млн транзакций банка с 200 признаками?",
              "correct_answer": "Использует leaf-wise рост деревьев и histogram-based splitting для разбиения"
            },
            {
              "level": "Senior",
              "question": "Как оптимизировать Gradient Boosting для скоринговой модели с несбалансированными классами (1:50) при строгом требовании latency inference < 100ms?",
              "correct_answer": "Использовать scale_pos_weight, уменьшить max_depth до 3-4, применить early stopping и DART dropout"
            }
          ]
        },
        {
          "theme": "Метрики качества и валидация моделей (Cross-validation, ROC-AUC, Precision-Recall, RMSE)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какая метрика показывает долю правильно предсказанных положительных классов среди всех предсказанных как положительные?",
              "correct_answer": "Precision (точность)"
            },
            {
              "level": "Middle",
              "question": "Банк строит модель скоринга с сильным дисбалансом классов (дефолтов 2%). Какую метрику лучше использовать вместо accuracy и почему?",
              "correct_answer": "ROC-AUC или PR-AUC, так как accuracy будет завышена из-за дисбаланса классов"
            },
            {
              "level": "Senior",
              "question": "При валидации антифрод-модели телеком-оператора на временных данных обнаружили, что ROC-AUC на обучении 0.92, на валидации 0.88, но precision@top-5% упал с 0.75 до 0.45. Какие архитектурные проблемы это выявляет?",
              "correct_answer": "Переобучение на паттернах мошенничества, temporal data drift, или неадекватная калибровка вероятностей модели"
            }
          ]
        },
        {
          "theme": "Feature Engineering и предобработка данных (масштабирование, кодирование категорий, работа с пропусками)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой метод sklearn используется для заполнения пропущенных значений средним или медианой в датасете клиентов банка?",
              "correct_answer": "SimpleImputer с параметрами strategy='mean' или strategy='median'"
            },
            {
              "level": "Middle",
              "question": "Вы строите модель скоринга для банка. Какой метод кодирования категорий выбрать для признака 'регион' с 17 областями Казахстана при высоком кардинале и риске переобучения?",
              "correct_answer": "Target Encoding или Frequency Encoding для снижения размерности"
            },
            {
              "level": "Senior",
              "question": "В телеком-компании признаки имеют разные распределения: трафик данных (степенное), длительность звонков (нормальное), баланс (с выбросами). Как спроектировать pipeline масштабирования для gradient boosting модели чтобы избежать data leakage?",
              "correct_answer": "RobustScaler внутри Pipeline с cross-validation, fit только на train fold"
            }
          ]
        }
      ]
    },
    {
      "competency": "MLOps инструменты (Airflow, MLflow)",
      "type": "DAILY",
      "importance": 70,
      "themes": [
        {
          "theme": "Организация и оркестрация ML-пайплайнов в Apache Airflow",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой оператор Airflow используется для запуска Python-функции в задаче ML-пайплайна?",
              "correct_answer": "PythonOperator"
            },
            {
              "level": "Middle",
              "question": "В чем разница между использования SubDagOperator и TaskGroup при организации сложного ML-пайплайна обработки транзакций?",
              "correct_answer": "TaskGroup группирует задачи визуально без создания отдельного DAG, SubDagOperator создаёт изолированный DAG"
            },
            {
              "level": "Senior",
              "question": "Почему динамическое создание задач через Dynamic Task Mapping предпочтительнее цикла при параллельном обучении моделей скоринга для разных регионов?",
              "correct_answer": "Задачи создаются в runtime, экономя память scheduler и позволяя масштабировать без перезапуска DAG"
            }
          ]
        },
        {
          "theme": "Управление экспериментами и версионирование моделей в MLflow",
          "questions": [
            {
              "level": "Junior",
              "question": "Какая команда MLflow используется для логирования обученной модели машинного обучения в эксперимент?",
              "correct_answer": "mlflow.log_model() или mlflow.<framework>.log_model()"
            },
            {
              "level": "Middle",
              "question": "В чем разница между версионированием моделей через MLflow Model Registry stages (Staging/Production) и версионированием через tags? Когда использовать каждый подход?",
              "correct_answer": "Stages управляют жизненным циклом и продвижением моделей, tags для метаданных и фильтрации"
            },
            {
              "level": "Senior",
              "question": "При миграции скоринговой модели из MLflow в production у вас возникла проблема: модель в Registry показывает разные результаты при inference через mlflow.pyfunc.load_model() и через REST API. Какие три наиболее вероятные причины?",
              "correct_answer": "Различия в preprocessing pipeline, несовпадение версий зависимостей, разная сериализация входных данных"
            }
          ]
        },
        {
          "theme": "Мониторинг и логирование ML-моделей в production",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой компонент MLflow используется для логирования метрик модели во время inference в production?",
              "correct_answer": "MLflow Tracking с методом log_metric"
            },
            {
              "level": "Middle",
              "question": "В чем разница между мониторингом data drift и concept drift при работе скоринговой модели в банке?",
              "correct_answer": "Data drift — изменение распределения входных данных, concept drift — изменение зависимости между признаками и целевой переменной"
            },
            {
              "level": "Senior",
              "question": "Модель оттока абонентов в телекоме показывает стабильные метрики качества, но бизнес-метрики упали. Какие проблемы мониторинга могли это пропустить?",
              "correct_answer": "Отсутствие мониторинга feature drift, задержек предсказаний, coverage модели и корреляции с бизнес-действиями"
            }
          ]
        },
        {
          "theme": "CI/CD для машинного обучения и автоматизация деплоя моделей",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой компонент MLflow используется для сохранения и версионирования обученных моделей машинного обучения?",
              "correct_answer": "MLflow Model Registry"
            },
            {
              "level": "Middle",
              "question": "Как в Airflow настроить автоматический ретрейн модели скоринга при деградации метрик на 5% от baseline?",
              "correct_answer": "Использовать BranchPythonOperator с проверкой метрик и условным запуском DAG ретрейна"
            },
            {
              "level": "Senior",
              "question": "Модель антифрода в production показывает latency 800ms вместо 200ms при A/B тесте. Какие узкие места проверить в пайплайне деплоя?",
              "correct_answer": "Сериализацию модели, отсутствие batch inference, избыточные feature transformations, network latency к feature store"
            }
          ]
        }
      ]
    },
    {
      "competency": "Big Data (Hadoop/Spark)",
      "type": "DAILY",
      "importance": 65,
      "themes": [
        {
          "theme": "Архитектура Hadoop: HDFS, MapReduce и YARN",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой фактор репликации по умолчанию использует HDFS для хранения блоков данных?",
              "correct_answer": "Три реплики для каждого блока данных"
            },
            {
              "level": "Middle",
              "question": "В каких случаях следует использовать YARN вместо MapReduce для обработки телеметрии абонентов телеком-оператора?",
              "correct_answer": "Когда нужна интеграция Spark, Flink или других движков обработки"
            },
            {
              "level": "Senior",
              "question": "Как диагностировать проблему медленного чтения транзакций клиентов банка из HDFS, если утилизация CPU и сети в норме?",
              "correct_answer": "Проверить IOPS дисков DataNode, балансировку блоков и долю локальных чтений"
            }
          ]
        },
        {
          "theme": "Apache Spark: RDD, DataFrame и оптимизация производительности",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой метод используется для создания RDD из текстового файла в Spark?",
              "correct_answer": "sparkContext.textFile() или sc.textFile()"
            },
            {
              "level": "Middle",
              "question": "В каком случае следует использовать DataFrame вместо RDD при обработке транзакций банковских клиентов?",
              "correct_answer": "Когда данные структурированы и нужна оптимизация через Catalyst optimizer"
            },
            {
              "level": "Senior",
              "question": "Почему при обработке CDR-записей абонентов возникает skew на этапе join по customer_id и как это исправить?",
              "correct_answer": "Неравномерное распределение ключей. Использовать salting или broadcast join для малых таблиц"
            }
          ]
        },
        {
          "theme": "Обработка потоковых данных с использованием Spark Streaming",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой метод используется для создания DStream из Kafka в Spark Streaming?",
              "correct_answer": "createDirectStream или createStream для интеграции с Kafka"
            },
            {
              "level": "Middle",
              "question": "В чем разница между window() и reduceByWindow() операциями при обработке транзакций банка в реальном времени?",
              "correct_answer": "window() возвращает все данные окна, reduceByWindow() агрегирует их функцией"
            },
            {
              "level": "Senior",
              "question": "Как решить проблему задержки обработки (processing delay > batch interval) при анализе CDR-записей телеком-оператора объемом 50K событий/сек?",
              "correct_answer": "Увеличить число партиций Kafka, параллелизм executors, уменьшить batch interval, оптимизировать shuffle"
            }
          ]
        },
        {
          "theme": "Интеграция Big Data инструментов: Hive, HBase и экосистема Hadoop",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой компонент Hadoop экосистемы позволяет выполнять SQL-подобные запросы к данным в HDFS?",
              "correct_answer": "Apache Hive"
            },
            {
              "level": "Middle",
              "question": "Когда стоит использовать HBase вместо Hive для хранения транзакционных данных клиентов банка?",
              "correct_answer": "Когда требуется быстрый доступ по ключу и обновления в реальном времени"
            },
            {
              "level": "Senior",
              "question": "Как решить проблему медленного выполнения JOIN между большой таблицей Hive с CDR данными и маленькой справочной таблицей HBase?",
              "correct_answer": "Использовать Map Join с кешированием справочника или Bulkload в Hive таблицу"
            }
          ]
        }
      ]
    }
  ]
}