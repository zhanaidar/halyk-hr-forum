{
  "profile": "Data Analyst",
  "specialization": "Data Analyst",
  "file_name": "Data_Analyst",
  "competencies": [
    {
      "competency": "SQL и работа с базами данных",
      "type": "CORE",
      "importance": 90,
      "themes": [
        {
          "theme": "Основы SQL: SELECT-запросы, фильтрация, сортировка и агрегатные функции",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой оператор SQL используется для фильтрации записей в таблице транзакций банка по сумме больше 100000 тенге?",
              "correct_answer": "WHERE для фильтрации строк по условию",
              "var_1": "GROUP BY с условием на сумму транзакций",
              "var_2": "WHERE для фильтрации строк по условию",
              "var_3": "FILTER применяется к строкам таблицы",
              "var_4": "HAVING для фильтрации по условию суммы",
              "correct_position": 2
            },
            {
              "level": "Middle",
              "question": "В чем разница между HAVING и WHERE при анализе количества звонков абонентов по тарифам в таблице телеком-оператора?",
              "correct_answer": "WHERE фильтрует до агрегации, HAVING после GROUP BY",
              "var_1": "HAVING применяется к JOIN, WHERE к подзапросам",
              "var_2": "WHERE работает с GROUP BY, HAVING с ORDER BY",
              "var_3": "HAVING фильтрует строки таблицы, WHERE проверяет агрегатные функции",
              "var_4": "WHERE фильтрует до агрегации, HAVING после GROUP BY",
              "correct_position": 4
            },
            {
              "level": "Senior",
              "question": "Почему запрос с COUNT(DISTINCT client_id) и WHERE по дате транзакции работает медленно на 50 млн записей? Как оптимизировать архитектуру выборки?",
              "correct_answer": "Создать составной индекс по дате и client_id, использовать партиционирование таблицы",
              "var_1": "Увеличить размер буферного пула и использовать покрывающий индекс только по client_id",
              "var_2": "Создать составной индекс по дате и client_id, использовать партиционирование таблицы",
              "var_3": "Денормализовать таблицу, добавив колонку с хешем client_id для ускорения подсчёта",
              "var_4": "Применить материализованное представление с предрасчётом COUNT по каждому клиенту ежедневно",
              "correct_position": 2
            }
          ]
        },
        {
          "theme": "JOIN-операции и объединение данных из множественных таблиц",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой тип JOIN вернет все записи из левой таблицы клиентов банка, даже если нет совпадений в таблице транзакций?",
              "correct_answer": "LEFT JOIN или LEFT OUTER JOIN",
              "var_1": "LEFT JOIN или LEFT OUTER JOIN",
              "var_2": "INNER JOIN с условием IS NULL",
              "var_3": "RIGHT JOIN или RIGHT OUTER JOIN",
              "var_4": "FULL JOIN с фильтром по левой таблице",
              "correct_position": 1
            },
            {
              "level": "Middle",
              "question": "В чем разница между INNER JOIN и CROSS JOIN при объединении таблицы абонентов (10 млн записей) с таблицей тарифных планов (50 записей)?",
              "correct_answer": "INNER JOIN возвращает совпадения по ключу, CROSS JOIN создает декартово произведение всех комбинаций",
              "var_1": "INNER JOIN объединяет по первичному ключу, CROSS JOIN использует внешние ключи для связи",
              "var_2": "INNER JOIN возвращает совпадения по ключу, CROSS JOIN создает декартово произведение всех комбинаций",
              "var_3": "INNER JOIN выполняется быстрее за счет индексации, CROSS JOIN сканирует таблицы последовательно",
              "var_4": "INNER JOIN фильтрует дубликаты абонентов, CROSS JOIN возвращает все записи без агрегации",
              "correct_position": 2
            },
            {
              "level": "Senior",
              "question": "Почему JOIN через подзапрос с GROUP BY выполняется медленнее, чем LEFT JOIN с агрегацией, при анализе транзакций клиентов за год (500+ млн записей)?",
              "correct_answer": "Подзапрос материализуется в памяти перед JOIN, LEFT JOIN с агрегацией использует индексы и потоковую обработку",
              "var_1": "LEFT JOIN блокирует таблицу для консистентности данных, подзапрос работает с snapshot isolation без блокировок",
              "var_2": "Подзапрос использует hash-агрегацию с параллелизмом, LEFT JOIN выполняет последовательное сканирование всех партиций",
              "var_3": "Подзапрос материализуется в памяти перед JOIN, LEFT JOIN с агрегацией использует индексы и потоковую обработку",
              "var_4": "LEFT JOIN создает декартово произведение перед фильтрацией, подзапрос оптимизирует выборку через временную таблицу",
              "correct_position": 3
            }
          ]
        },
        {
          "theme": "Оконные функции и аналитические запросы для сложных вычислений",
          "questions": [
            {
              "level": "Junior",
              "question": "Какая оконная функция используется для присвоения порядкового номера каждой строке в результате запроса по транзакциям клиентов банка?",
              "correct_answer": "ROW_NUMBER() OVER (ORDER BY column_name)",
              "var_1": "RANK() OVER (PARTITION BY customer_id)",
              "var_2": "NTILE(100) OVER (ORDER BY transaction_date)",
              "var_3": "DENSE_RANK() без указания ORDER BY",
              "var_4": "ROW_NUMBER() OVER (ORDER BY column_name)",
              "correct_position": 4
            },
            {
              "level": "Middle",
              "question": "В чем разница между RANK() и DENSE_RANK() при анализе топ-10 клиентов телеком оператора по объему трафика с одинаковыми значениями?",
              "correct_answer": "RANK() пропускает следующие номера после дубликатов, DENSE_RANK() присваивает последовательные номера",
              "var_1": "RANK() пропускает следующие номера после дубликатов, DENSE_RANK() присваивает последовательные номера",
              "var_2": "RANK() учитывает NULL значения в начале, DENSE_RANK() игнорирует их полностью",
              "var_3": "RANK() группирует дубликаты отдельной строкой, DENSE_RANK() объединяет их в агрегат",
              "var_4": "RANK() сортирует по возрастанию, DENSE_RANK() всегда применяет сортировку по убыванию",
              "correct_position": 1
            },
            {
              "level": "Senior",
              "question": "Почему использование оконных функций с PARTITION BY предпочтительнее подзапросов с GROUP BY при расчете скользящих средних балансов по 10 миллионам счетов банка?",
              "correct_answer": "Избегается повторное сканирование таблицы, сортировка выполняется однократно, снижается нагрузка на memory и tempdb",
              "var_1": "Оконные функции автоматически создают индексы для PARTITION BY, ускоряя выборку данных из больших таблиц",
              "var_2": "Избегается повторное сканирование таблицы, сортировка выполняется однократно, снижается нагрузка на memory и tempdb",
              "var_3": "GROUP BY требует блокировки таблицы на запись, оконные функции работают в режиме READ UNCOMMITTED изолированно",
              "var_4": "Подзапросы загружают все данные в оперативную память сервера, оконные функции используют потоковую обработку данных",
              "correct_position": 2
            }
          ]
        },
        {
          "theme": "Оптимизация запросов, индексы и анализ производительности баз данных",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой тип индекса создается по умолчанию при определении PRIMARY KEY в PostgreSQL?",
              "correct_answer": "B-tree индекс создается автоматически для PRIMARY KEY",
              "var_1": "Hash индекс создается автоматически для PRIMARY KEY",
              "var_2": "Уникальный GiST индекс генерируется для PRIMARY KEY",
              "var_3": "B-tree индекс создается автоматически для PRIMARY KEY",
              "var_4": "Clustered индекс создается по умолчанию для PRIMARY KEY",
              "correct_position": 3
            },
            {
              "level": "Middle",
              "question": "В таблице транзакций банка 50 млн записей. Запрос с WHERE status = 'pending' выполняется 40 секунд, хотя индекс на status существует. В чем вероятная причина?",
              "correct_answer": "Низкая селективность индекса из-за малого количества уникальных значений",
              "var_1": "Отсутствие покрывающего индекса приводит к дополнительным обращениям к таблице",
              "var_2": "Низкая селективность индекса из-за малого количества уникальных значений",
              "var_3": "Фрагментация индекса требует выполнения операции REBUILD для восстановления",
              "var_4": "Индекс не используется из-за неявного преобразования типов данных",
              "correct_position": 2
            },
            {
              "level": "Senior",
              "question": "При партиционировании таблицы звонков телеком-оператора по месяцам аналитические запросы с JOIN стали медленнее. Как оптимизировать архитектуру без изменения партиционирования?",
              "correct_answer": "Создать локальные индексы на каждой партиции и использовать partition-wise join",
              "var_1": "Создать локальные индексы на каждой партиции и использовать partition-wise join",
              "var_2": "Настроить hash-партиционирование таблиц для равномерного распределения JOIN операций",
              "var_3": "Применить глобальные индексы и настроить параллельное выполнение запросов",
              "var_4": "Использовать материализованные представления с агрегацией данных по партициям",
              "correct_position": 1
            }
          ]
        }
      ]
    },
    {
      "competency": "Визуализация данных (Tableau, Power BI, Looker)",
      "type": "CORE",
      "importance": 85,
      "themes": [
        {
          "theme": "Основы визуализации: выбор типов диаграмм и графиков для различных данных",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой тип диаграммы следует использовать для отображения динамики количества банковских транзакций по месяцам за год?",
              "correct_answer": "Линейный график или столбчатая диаграмма для временных рядов",
              "var_1": "Тепловая карта для анализа распределения транзакций по времени",
              "var_2": "Точечная диаграмма для визуализации корреляции между периодами",
              "var_3": "Круговая диаграмма для отображения долей транзакций по месяцам",
              "var_4": "Линейный график или столбчатая диаграмма для временных рядов",
              "correct_position": 4
            },
            {
              "level": "Middle",
              "question": "В чем разница между использованием тепловой карты и столбчатой диаграммы при анализе активности абонентов телеком-оператора по часам и дням недели?",
              "correct_answer": "Тепловая карта показывает паттерны двух измерений одновременно, столбчатая требует фильтрации",
              "var_1": "Столбчатая диаграмма отображает плотность распределения, тепловая карта показывает тренды",
              "var_2": "Тепловая карта требует агрегации данных, столбчатая работает с детальными значениями",
              "var_3": "Тепловая карта показывает паттерны двух измерений одновременно, столбчатая требует фильтрации",
              "var_4": "Столбчатая диаграмма лучше показывает корреляции между временными интервалами и днями",
              "correct_position": 3
            },
            {
              "level": "Senior",
              "question": "Почему для дашборда с метриками реального времени по fraud-транзакциям в банке следует избегать круговых диаграмм и использовать KPI-карточки с спарклайнами?",
              "correct_answer": "Круговые диаграммы затрудняют быстрое сравнение значений, спарклайны показывают тренд и текущее значение мгновенно",
              "var_1": "Круговые диаграммы затрудняют быстрое сравнение значений, спарклайны показывают тренд и текущее значение мгновенно",
              "var_2": "Круговые диаграммы требуют больше вычислительных ресурсов при обновлении данных в реальном времени",
              "var_3": "Спарклайны обеспечивают лучшую производительность рендеринга при высокой частоте обновления метрик fraud-детекции",
              "var_4": "Круговые диаграммы занимают больше экранного пространства и снижают информационную плотность дашборда",
              "correct_position": 1
            }
          ]
        },
        {
          "theme": "Создание интерактивных дашбордов и настройка фильтров",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой тип фильтра в Tableau позволяет пользователю выбирать диапазон дат для анализа транзакций банка?",
              "correct_answer": "Фильтр диапазона дат (Date Range Filter)",
              "var_1": "Контекстный фильтр по измерению даты",
              "var_2": "Параметр с отдельным календарным селектором",
              "var_3": "Фильтр диапазона дат (Date Range Filter)",
              "var_4": "Фильтр типа Wildcard для временных значений",
              "correct_position": 3
            },
            {
              "level": "Middle",
              "question": "В Power BI для дашборда телеком-оператора нужно показывать данные по регионам Казахстана. Какой тип фильтра эффективнее для связи между несколькими визуализациями - Page level или Report level, и почему?",
              "correct_answer": "Report level, обеспечивает единую фильтрацию для всех страниц отчета",
              "var_1": "Report level, обеспечивает единую фильтрацию для всех страниц отчета",
              "var_2": "Visual level, синхронизирует фильтры между связанными визуализациями автоматически",
              "var_3": "Drill-through фильтр, обеспечивает кросс-страничную навигацию по регионам",
              "var_4": "Page level, применяет фильтрацию только к текущей странице дашборда",
              "correct_position": 1
            },
            {
              "level": "Senior",
              "question": "Дашборд банка с 15 млн записи транзакций тормозит при использовании каскадных фильтров в Tableau. Какую архитектурную оптимизацию применить для улучшения производительности без потери функциональности?",
              "correct_answer": "Агрегация данных в источнике, использование экстрактов с индексацией и Context Filters",
              "var_1": "Переход на Hyper экстракты с отключением индексации и добавлением кэширования результатов",
              "var_2": "Увеличение оперативной памяти сервера Tableau и настройка параллельных запросов к источнику",
              "var_3": "Применение Live Connection с материализованными представлениями и партиционированием по датам транзакций",
              "var_4": "Агрегация данных в источнике, использование экстрактов с индексацией и Context Filters",
              "correct_position": 4
            }
          ]
        },
        {
          "theme": "Оптимизация производительности отчетов и работа с большими объемами данных",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой тип соединения данных в Tableau обеспечивает максимальную производительность при работе с большими объемами транзакционных данных банка?",
              "correct_answer": "Extract (выгрузка данных)",
              "var_1": "Live connection (прямое подключение)",
              "var_2": "Extract (выгрузка данных)",
              "var_3": "Published data source (опубликованный источник)",
              "var_4": "Federated query (федеративный запрос)",
              "correct_position": 2
            },
            {
              "level": "Middle",
              "question": "В Power BI дашборд с 50 млн записей абонентов телеком-оператора загружается 2 минуты. Какие два метода оптимизации применить в первую очередь?",
              "correct_answer": "Агрегация данных на уровне источника и использование DirectQuery вместо Import",
              "var_1": "Агрегация данных на уровне источника и использование DirectQuery вместо Import",
              "var_2": "Увеличение памяти сервера и добавление индексов в визуальные элементы",
              "var_3": "Параллельная загрузка таблиц и включение кэширования на уровне DAX",
              "var_4": "Партиционирование таблиц по датам и использование инкрементального обновления",
              "correct_position": 1
            },
            {
              "level": "Senior",
              "question": "Как спроектировать архитектуру отчетности в Tableau для банка с 200+ отчетов и 5TB данных, чтобы минимизировать нагрузку на продуктивную БД и обеспечить обновление данных каждые 15 минут?",
              "correct_answer": "Внедрить промежуточный слой с агрегированными extract'ами, инкрементальным обновлением и материализованными представлениями в отдельной аналитической БД",
              "var_1": "Внедрить промежуточный слой с агрегированными extract'ами, инкрементальным обновлением и материализованными представлениями в отдельной аналитической БД",
              "var_2": "Настроить репликацию продуктивной БД в реальном времени и подключать все отчеты напрямую к реплике с партиционированием таблиц",
              "var_3": "Использовать живые подключения к продуктивной БД с кешированием запросов на уровне Tableau Server и индексацией таблиц",
              "var_4": "Создать единый гипер-extract на все отчеты с полным обновлением каждые 15 минут и распределением нагрузки через Tableau Bridge",
              "correct_position": 1
            }
          ]
        },
        {
          "theme": "Продвинутые вычисления: LOD-выражения, DAX-формулы и кастомные метрики",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой синтаксис используется для создания базового LOD-выражения FIXED в Tableau для расчета общей суммы транзакций по клиенту?",
              "correct_answer": "{FIXED [Customer_ID] : SUM([Transaction_Amount])}",
              "var_1": "{INCLUDE [Customer_ID] : SUM([Transaction_Amount])}",
              "var_2": "{FIXED [Customer_ID] : SUM([Transaction_Amount])}",
              "var_3": "CALCULATE(SUM([Transaction_Amount]), ALLEXCEPT(Customer_ID))",
              "var_4": "{LOD FIXED [Customer_ID] = SUM([Transaction_Amount])}",
              "correct_position": 2
            },
            {
              "level": "Middle",
              "question": "В Power BI для витрины телеком-оператора нужно посчитать среднюю выручку по абоненту независимо от фильтров дашборда. Какую функцию DAX использовать: CALCULATE с ALL или простое AVERAGE?",
              "correct_answer": "CALCULATE с ALL для игнорирования контекста фильтров",
              "var_1": "CALCULATE с FILTER для пересчета контекста строк",
              "var_2": "CALCULATE с ALL для игнорирования контекста фильтров",
              "var_3": "AVERAGE с параметром ALLSELECTED для частичного игнорирования",
              "var_4": "AVERAGEX с итерацией по таблице фактов",
              "correct_position": 2
            },
            {
              "level": "Senior",
              "question": "В банковском дашборде с 50М транзакций LOD-выражения INCLUDE вызывают таймауты при расчете конверсии по продуктам. Как оптимизировать архитектуру расчета метрик?",
              "correct_answer": "Перенести агрегацию в ETL-слой с материализованными таблицами и использовать предрасчитанные метрики",
              "var_1": "Использовать FIXED вместо INCLUDE и добавить индексы на таблицы источника данных",
              "var_2": "Включить параллельные запросы Tableau Server и увеличить кеш экстрактов до 128GB",
              "var_3": "Перенести агрегацию в ETL-слой с материализованными таблицами и использовать предрасчитанные метрики",
              "var_4": "Применить инкрементальный refresh экстрактов с фильтрами контекста на уровне источника",
              "correct_position": 3
            }
          ]
        }
      ]
    },
    {
      "competency": "Excel (продвинутый уровень)",
      "type": "CORE",
      "importance": 80,
      "themes": [
        {
          "theme": "Сводные таблицы и многомерный анализ данных (PivotTables, слайсеры, вычисляемые поля)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой инструмент в сводной таблице Excel позволяет быстро фильтровать данные по нескольким полям одновременно без изменения структуры отчета?",
              "correct_answer": "Слайсеры (Slicers)",
              "var_1": "Фильтры отчета (Report Filters)",
              "var_2": "Группировка данных (Grouping)",
              "var_3": "Вычисляемые поля (Calculated Fields)",
              "var_4": "Слайсеры (Slicers)",
              "correct_position": 4
            },
            {
              "level": "Middle",
              "question": "В банке нужно анализировать транзакции клиентов: сумма, комиссия и чистая выручка. Когда следует использовать вычисляемое поле вместо вычисляемого элемента в сводной таблице?",
              "correct_answer": "Когда расчет выполняется между разными полями, а не внутри одного поля",
              "var_1": "Когда требуется группировка транзакций по датам с применением фильтров слайсеров",
              "var_2": "Когда расчет выполняется между разными полями, а не внутри одного поля",
              "var_3": "Когда нужно суммировать данные по нескольким измерениям одновременно в строках",
              "var_4": "Когда расчет производится внутри одного поля для категорий значений",
              "correct_position": 2
            },
            {
              "level": "Senior",
              "question": "Почему при проектировании сводных таблиц для анализа абонентской базы телеком-оператора критически важно избегать объединенных ячеек и пустых строк в исходных данных?",
              "correct_answer": "Нарушается структура таблицы, Excel не распознает непрерывный диапазон данных для анализа",
              "var_1": "Нарушается корректность работы слайсеров и фильтров при группировке по датам",
              "var_2": "Снижается производительность пересчёта формул и увеличивается время загрузки сводной таблицы",
              "var_3": "Нарушается структура таблицы, Excel не распознает непрерывный диапазон данных для анализа",
              "var_4": "Возникают ошибки при создании вычисляемых полей с использованием функций агрегации",
              "correct_position": 3
            }
          ]
        },
        {
          "theme": "Продвинутые функции для работы с данными (INDEX-MATCH, XLOOKUP, массивы, FILTER, UNIQUE)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой синтаксис функции XLOOKUP для поиска клиента по БИН в таблице банковских контрагентов?",
              "correct_answer": "=XLOOKUP(искомое_значение, массив_поиска, массив_возврата, [если_не_найдено])",
              "var_1": "=XLOOKUP(массив_поиска, искомое_значение, массив_возврата, [критерий_сопоставления])",
              "var_2": "=XLOOKUP(значение_поиска, столбец_возврата, столбец_поиска, [направление])",
              "var_3": "=XLOOKUP(БИН, диапазон_БИН:диапазон_данных, режим_поиска)",
              "var_4": "=XLOOKUP(искомое_значение, массив_поиска, массив_возврата, [если_не_найдено])",
              "correct_position": 4
            },
            {
              "level": "Middle",
              "question": "Когда следует использовать связку INDEX-MATCH вместо XLOOKUP при анализе данных абонентов телеком-оператора с 500K строк?",
              "correct_answer": "Для совместимости с версиями Excel старше 2021 и оптимизации производительности",
              "var_1": "Когда требуется поиск по нескольким критериям с агрегацией результатов",
              "var_2": "Для совместимости с версиями Excel старше 2021 и оптимизации производительности",
              "var_3": "При необходимости возврата нескольких столбцов одновременно через массивы constantes",
              "var_4": "Для двунаправленного поиска в таблицах с динамическими диапазонами данных",
              "correct_position": 2
            },
            {
              "level": "Senior",
              "question": "Как спроектировать систему динамических отчетов по транзакциям банка используя FILTER и UNIQUE, чтобы избежать пересчета при изменении исходных данных?",
              "correct_answer": "Использовать структурированные таблицы с именованными диапазонами и разделить фильтрацию по слоям данных",
              "var_1": "Использовать структурированные таблицы с именованными диапазонами и разделить фильтрацию по слоям данных",
              "var_2": "Настроить Power Query для автоматического обновления и кэширования результатов фильтрации в памяти",
              "var_3": "Применить волатильные формулы с INDIRECT и создать динамические ссылки на диапазоны данных",
              "var_4": "Создать сводные таблицы с автообновлением и связать их через GETPIVOTDATA для динамики",
              "correct_position": 1
            }
          ]
        },
        {
          "theme": "Автоматизация и оптимизация через Power Query (ETL-процессы, M-язык, объединение источников)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какая функция в Power Query используется для объединения нескольких таблиц по вертикали (добавление строк)?",
              "correct_answer": "Table.Combine или Append Queries",
              "var_1": "Table.Join или Merge Queries",
              "var_2": "Table.Combine или Append Queries",
              "var_3": "List.Union для таблиц",
              "var_4": "Table.NestedJoin с параметром Inner",
              "correct_position": 2
            },
            {
              "level": "Middle",
              "question": "В банке нужно ежедневно загружать данные транзакций из 50 филиалов (CSV файлы в одной папке). Какой подход в Power Query оптимален для автоматизации загрузки всех файлов одновременно?",
              "correct_answer": "Использовать From Folder с последующим Combine Files",
              "var_1": "Использовать Get Data из Web с параметрами",
              "var_2": "Применить Append Queries для каждого CSV вручную",
              "var_3": "Использовать From Folder с последующим Combine Files",
              "var_4": "Создать 50 отдельных запросов From File",
              "correct_position": 3
            },
            {
              "level": "Senior",
              "question": "При проектировании ETL-процесса для телеком-оператора с множественными источниками данных, почему критически важно использовать Query Folding, и в каких случаях он не работает?",
              "correct_answer": "Переносит вычисления на сервер БД для производительности; не работает после пользовательских функций и некоторых трансформаций M-языка",
              "var_1": "Автоматически распараллеливает запросы между источниками; блокируется при использовании Reference и merge операций с параметрами",
              "var_2": "Кеширует промежуточные результаты в памяти; прекращает работу при превышении лимита в 1GB или использовании Table.Buffer",
              "var_3": "Оптимизирует M-код через компиляцию в native код; отключается при работе с JSON/XML источниками и веб-сервисами",
              "var_4": "Переносит вычисления на сервер БД для производительности; не работает после пользовательских функций и некоторых трансформаций M-языка",
              "correct_position": 4
            }
          ]
        },
        {
          "theme": "Визуализация данных и интерактивные дашборды (условное форматирование, спарклайны, срезы, динамические диаграммы)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой инструмент Excel используется для создания миниатюрных графиков в одной ячейке для отображения динамики показателей KPI?",
              "correct_answer": "Спарклайны (Sparklines)",
              "var_1": "Спарклайны (Sparklines)",
              "var_2": "Микродиаграммы (Micro Charts)",
              "var_3": "Условное форматирование (Conditional Formatting)",
              "var_4": "Срезы данных (Slicers)",
              "correct_position": 1
            },
            {
              "level": "Middle",
              "question": "В отчете по транзакциям клиентов банка нужно визуально выделить суммы выше 5 млн тенге красным, а ниже 100 тыс — серым. Какой метод оптимален и почему?",
              "correct_answer": "Условное форматирование с правилами на основе значений — автоматически обновляется при изменении данных",
              "var_1": "Условное форматирование с правилами на основе значений — автоматически обновляется при изменении данных",
              "var_2": "Макрос VBA с циклом проверки значений ячеек и применением цветовой заливки",
              "var_3": "Спарклайны с настройкой цветовых маркеров для критических значений транзакций клиентов",
              "var_4": "Функция ЕСЛИ с вложенной функцией ЯЧЕЙКА для установки формата по условию",
              "correct_position": 1
            },
            {
              "level": "Senior",
              "question": "При проектировании интерактивного дашборда для мониторинга абонентской базы телеком-оператора с 12 регионами и 8 тарифами, какую архитектуру визуализации вы выберете для обеспечения производительности и удобства анализа?",
              "correct_answer": "Сводная таблица с срезами, динамические диаграммы на именованных диапазонах, разделение данных и визуализации на отдельные листы",
              "var_1": "Сводная таблица с срезами, динамические диаграммы на именованных диапазонах, разделение данных и визуализации на отдельные листы",
              "var_2": "Power Query для ETL, единая сводная таблица на главном листе со всеми срезами и встроенными диаграммами",
              "var_3": "Несколько связанных сводных таблиц с общими фильтрами, статические диаграммы на ячейках через СМЕЩ и ИНДЕКС",
              "var_4": "Условное форматирование с градиентами, спарклайны для трендов, макросы VBA для автоматического обновления визуализаций по кнопке",
              "correct_position": 1
            }
          ]
        }
      ]
    },
    {
      "competency": "Статистический анализ и A/B тестирование",
      "type": "DAILY",
      "importance": 60,
      "themes": [
        {
          "theme": "Основы статистических тестов: t-тест, z-тест, хи-квадрат и условия их применения",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой статистический тест используется для сравнения средних значений двух групп с неизвестной дисперсией генеральной совокупности?",
              "correct_answer": "t-тест Стьюдента для независимых выборок",
              "var_1": "парный t-тест для связанных наблюдений",
              "var_2": "z-тест для нормально распределённых выборок",
              "var_3": "критерий хи-квадрат для сравнения средних",
              "var_4": "t-тест Стьюдента для независимых выборок",
              "correct_position": 4
            },
            {
              "level": "Middle",
              "question": "В A/B тесте новой функции мобильного банкинга участвуют 50 пользователей в каждой группе. Конверсия группы А: 12%, группы B: 18%. Какой тест применить и почему?",
              "correct_answer": "Хи-квадрат тест, так как сравниваются пропорции категориальных данных",
              "var_1": "Точный тест Фишера, поскольку размер выборок превышает 30 наблюдений",
              "var_2": "Z-тест для пропорций, так как сравниваются две независимые выборки",
              "var_3": "Хи-квадрат тест, так как сравниваются пропорции категориальных данных",
              "var_4": "T-тест Стьюдента для независимых выборок с категориальными данными",
              "correct_position": 3
            },
            {
              "level": "Senior",
              "question": "При A/B тесте тарифного плана телеком-оператора p-value составил 0.048, но размер эффекта минимальный (0.3%). Какую проблему это выявляет и как решать?",
              "correct_answer": "Статистическая значимость без практической значимости из-за большой выборки, использовать минимальный детектируемый эффект",
              "var_1": "Статистическая значимость без практической значимости из-за большой выборки, использовать минимальный детектируемый эффект",
              "var_2": "Множественное тестирование без поправки Бонферрони, применить корректировку уровня значимости на число гипотез",
              "var_3": "Ошибка первого рода из-за низкого порога значимости, увеличить альфа до 0.10 для корректировки",
              "var_4": "Недостаточная мощность теста привела к ложноположительному результату, увеличить размер выборки для валидации",
              "correct_position": 1
            }
          ]
        },
        {
          "theme": "Дизайн и проведение A/B тестов: размер выборки, статистическая мощность и длительность эксперимента",
          "questions": [
            {
              "level": "Junior",
              "question": "Что такое статистическая мощность (power) в A/B тестировании?",
              "correct_answer": "Вероятность обнаружить эффект, когда он реально существует",
              "var_1": "Доля пользователей, необходимая для корректного завершения эксперимента",
              "var_2": "Вероятность ошибочно отклонить нулевую гипотезу при тестировании",
              "var_3": "Минимальный размер выборки для достижения статистической значимости",
              "var_4": "Вероятность обнаружить эффект, когда он реально существует",
              "correct_position": 4
            },
            {
              "level": "Middle",
              "question": "Банк тестирует новый интерфейс мобильного приложения. Конверсия в заявку на кредит 2%, MDE 0.3%, α=0.05, β=0.2. Какой минимальный размер выборки нужен для каждой группы?",
              "correct_answer": "Около 43 500 пользователей на группу",
              "var_1": "Около 87 000 пользователей на группу",
              "var_2": "Около 8 700 пользователей на группу",
              "var_3": "Около 43 500 пользователей на группу",
              "var_4": "Около 17 300 пользователей на группу",
              "correct_position": 3
            },
            {
              "level": "Senior",
              "question": "В телеком компании A/B тест на изменение тарифного плана показал значимый результат на 3-й день (p=0.03), но вы продолжили эксперимент. Почему это правильное решение и какие риски раннего завершения?",
              "correct_answer": "Избежать эффекта новизны и peeking bias, минимизировать ложноположительные результаты",
              "var_1": "Избежать эффекта новизны и peeking bias, минимизировать ложноположительные результаты",
              "var_2": "Дождаться равномерного распределения трафика между контрольной и тестовой группами",
              "var_3": "Увеличить статистическую мощность и достичь целевого размера выборки по формуле",
              "var_4": "Собрать больше данных для сегментации пользователей по демографическим признакам",
              "correct_position": 1
            }
          ]
        },
        {
          "theme": "Интерпретация результатов A/B тестов: p-value, доверительные интервалы и практическая значимость",
          "questions": [
            {
              "level": "Junior",
              "question": "Что означает p-value = 0.03 в результатах A/B теста новой версии мобильного приложения банка?",
              "correct_answer": "Вероятность получить такой результат случайно составляет 3%",
              "var_1": "Доверительный интервал составляет 97% для данного теста",
              "var_2": "Вероятность получить такой результат случайно составляет 3%",
              "var_3": "Новая версия улучшает метрику на 3% относительно контроля",
              "var_4": "Статистическая мощность теста достигла порога в 3%",
              "correct_position": 2
            },
            {
              "level": "Middle",
              "question": "В A/B тесте тарифа связи p-value = 0.04, но прирост конверсии 0.2%. Какое решение принять и почему?",
              "correct_answer": "Отклонить изменения, результат статистически значим, но не практически значим",
              "var_1": "Отклонить изменения, результат статистически значим, но не практически значим",
              "var_2": "Продлить тест для увеличения размера выборки и мощности",
              "var_3": "Принять изменения с осторожностью, учитывая статистическую значимость результата",
              "var_4": "Внедрить изменения, p-value ниже порога 0.05 подтверждает эффект",
              "correct_position": 1
            },
            {
              "level": "Senior",
              "question": "A/B тест кредитной формы показал p-value = 0.001, но через неделю эффект исчез. Какие причины и как диагностировать?",
              "correct_answer": "Проверить эффект новизны, сезонность, изменение трафика и сегментировать пользователей",
              "var_1": "Пересчитать p-value с поправкой Бонферрони для множественных сравнений по дням",
              "var_2": "Применить байесовский подход для оценки апостериорной вероятности эффекта",
              "var_3": "Увеличить размер выборки и повторить тест с более строгим alpha-уровнем",
              "var_4": "Проверить эффект новизны, сезонность, изменение трафика и сегментировать пользователей",
              "correct_position": 4
            }
          ]
        },
        {
          "theme": "Продвинутые методы тестирования: A/A тесты, множественное тестирование и байесовский подход",
          "questions": [
            {
              "level": "Junior",
              "question": "Что такое A/A тест и для чего он используется перед запуском A/B теста?",
              "correct_answer": "Тест с идентичными вариантами для проверки корректности системы сплитования и отсутствия ложных срабатываний.",
              "var_1": "Предварительный тест на меньшей выборке для оценки необходимого размера выборки основного A/B теста.",
              "var_2": "Параллельный запуск двух A/B тестов на разных сегментах для проверки консистентности результатов эксперимента.",
              "var_3": "Тест с идентичными вариантами для проверки корректности системы сплитования и отсутствия ложных срабатываний.",
              "var_4": "Тест двух вариантов с минимальными различиями для калибровки чувствительности метрик перед основным экспериментом.",
              "correct_position": 3
            },
            {
              "level": "Middle",
              "question": "В банке проводится 20 A/B тестов одновременно на разных фичах мобильного приложения. Какой метод коррекции p-value следует применить для контроля множественного тестирования?",
              "correct_answer": "Метод Бонферрони или менее консервативный Холма-Бонферрони для контроля FWER.",
              "var_1": "Bootstrap-ресемплинг с доверительными интервалами для каждого теста независимо",
              "var_2": "Метод Бонферрони или менее консервативный Холма-Бонферрони для контроля FWER.",
              "var_3": "Увеличение размера выборки пропорционально количеству тестов для сохранения мощности",
              "var_4": "Метод False Discovery Rate (FDR) с порогом q-value 0.05",
              "correct_position": 2
            },
            {
              "level": "Senior",
              "question": "Телеком компания тестирует новый тарифный план. Частотный A/B тест показал p-value=0.08, но байесовский подход с prior на основе исторических данных дает вероятность успеха 92%. Как принять решение и почему?",
              "correct_answer": "Использовать байесовский результат, так как prior включает релевантную историческую информацию и учитывает бизнес-контекст лучше произвольного порога значимости.",
              "var_1": "Провести дополнительный A/B тест с увеличенной выборкой до достижения p-value<0.05, затем сравнить с байесовским результатом.",
              "var_2": "Использовать байесовский результат, так как prior включает релевантную историческую информацию и учитывает бизнес-контекст лучше произвольного порога значимости.",
              "var_3": "Усреднить оба подхода: применить взвешенную комбинацию частотного и байесовского результатов для принятия сбалансированного решения.",
              "var_4": "Отклонить гипотезу о различиях, так как p-value превышает стандартный порог 0.05 и статистическая значимость не достигнута.",
              "correct_position": 2
            }
          ]
        }
      ]
    },
    {
      "competency": "Python для анализа данных (pandas, matplotlib)",
      "type": "DAILY",
      "importance": 70,
      "themes": [
        {
          "theme": "Загрузка и первичная обработка данных в pandas (чтение файлов, фильтрация, сортировка, обработка пропусков)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой метод pandas используется для чтения CSV-файла с транзакциями клиентов банка?",
              "correct_answer": "pd.read_csv()",
              "var_1": "pd.import_csv()",
              "var_2": "pd.open_csv()",
              "var_3": "pd.read_csv()",
              "var_4": "pd.load_csv()",
              "correct_position": 3
            },
            {
              "level": "Middle",
              "question": "В чем разница между dropna() и fillna() при обработке пропусков в данных абонентов? Когда использовать каждый метод?",
              "correct_answer": "dropna() удаляет строки с пропусками, fillna() заполняет значениями. Используй fillna() для критичных полей.",
              "var_1": "dropna() заполняет средним значением, fillna() удаляет дубликаты. Используй dropna() для числовых колонок.",
              "var_2": "dropna() заменяет на ноль, fillna() удаляет колонки. Используй fillna() для категориальных признаков абонентов.",
              "var_3": "dropna() удаляет строки с пропусками, fillna() заполняет значениями. Используй fillna() для критичных полей.",
              "var_4": "fillna() удаляет строки с пропусками, dropna() интерполирует значения. Используй dropna() для временных рядов.",
              "correct_position": 3
            },
            {
              "level": "Senior",
              "question": "При загрузке 50GB лог-файлов транзакций банка pandas выдает MemoryError. Какие три подхода решат проблему без изменения железа?",
              "correct_answer": "Использовать chunksize в read_csv, dtype optimization, или dask/polars вместо pandas.",
              "var_1": "Использовать chunksize в read_csv, dtype optimization, или dask/polars вместо pandas.",
              "var_2": "Применить read_csv с параметром low_memory=False, engine='python', encoding optimization.",
              "var_3": "Увеличить swap память, использовать gc.collect() после каждой операции, компрессия gzip.",
              "var_4": "Использовать numpy.memmap для прямого доступа, pandas.set_option('memory_mode', 'low'), индексация.",
              "correct_position": 1
            }
          ]
        },
        {
          "theme": "Агрегация и группировка данных (groupby, pivot_table, merge, join операции)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой метод pandas используется для группировки данных по одному или нескольким столбцам перед применением агрегирующих функций?",
              "correct_answer": "groupby()",
              "var_1": "pivot_table()",
              "var_2": "groupby()",
              "var_3": "transform()",
              "var_4": "aggregate()",
              "correct_position": 2
            },
            {
              "level": "Middle",
              "question": "В чем разница между merge() с параметром how='left' и how='inner' при объединении таблицы транзакций клиентов банка с таблицей профилей?",
              "correct_answer": "left сохраняет все транзакции даже без профиля, inner только совпадения",
              "var_1": "left выполняет outer join с приоритетом, inner делает cross join",
              "var_2": "left сохраняет все транзакции даже без профиля, inner только совпадения",
              "var_3": "left объединяет по левому индексу, inner по обоим ключам таблиц",
              "var_4": "inner сохраняет все записи обеих таблиц, left только левую таблицу",
              "correct_position": 2
            },
            {
              "level": "Senior",
              "question": "При агрегации 50 млн записей звонков абонентов телеком оператора groupby работает медленно. Какие подходы оптимизации применить для ускорения?",
              "correct_answer": "Использовать categorical dtype, предварительно отсортировать данные, применить chunking или dask",
              "var_1": "Переключиться на iterrows с ручной агрегацией, использовать defaultdict для накопления результатов",
              "var_2": "Применить vectorization вместо groupby, использовать NumPy arrays для агрегаций",
              "var_3": "Увеличить RAM, использовать multiprocessing.Pool, индексировать DataFrame перед группировкой",
              "var_4": "Использовать categorical dtype, предварительно отсортировать данные, применить chunking или dask",
              "correct_position": 4
            }
          ]
        },
        {
          "theme": "Визуализация данных с помощью matplotlib (линейные графики, гистограммы, scatter plots, настройка стилей)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой метод matplotlib используется для создания линейного графика из pandas DataFrame?",
              "correct_answer": "df.plot() или plt.plot()",
              "var_1": "df.line() или plt.chart()",
              "var_2": "df.plot() или plt.plot()",
              "var_3": "df.draw_line() или plt.graph()",
              "var_4": "df.visualize() или plt.line()",
              "correct_position": 2
            },
            {
              "level": "Middle",
              "question": "В чем разница между plt.subplot() и plt.subplots() при создании дашборда с метриками транзакций банка?",
              "correct_answer": "plt.subplots() создает все оси сразу и возвращает массив, удобнее для множественных графиков",
              "var_1": "plt.subplot() поддерживает интерактивное добавление графиков, plt.subplots() требует предварительного планирования структуры",
              "var_2": "plt.subplots() автоматически синхронизирует оси графиков, plt.subplot() создает независимые координатные системы",
              "var_3": "plt.subplots() создает все оси сразу и возвращает массив, удобнее для множественных графиков",
              "var_4": "plt.subplot() использует GridSpec для гибкой компоновки, plt.subplots() создает только регулярную сетку",
              "correct_position": 3
            },
            {
              "level": "Senior",
              "question": "Почему при визуализации 500K транзакций за месяц на scatter plot происходит падение производительности и как это решить?",
              "correct_answer": "Overplotting и memory overhead. Использовать hexbin, datashader, агрегацию данных или rasterized=True",
              "var_1": "Overplotting и memory overhead. Использовать hexbin, datashader, агрегацию данных или rasterized=True",
              "var_2": "Недостаточно RAM для отрисовки точек. Использовать plt.scatter с параметром s=1 и уменьшить DPI",
              "var_3": "Блокировка главного потока при построении. Применить plt.ion() для интерактивного режима и async plotting",
              "var_4": "Медленный рендеринг matplotlib. Переключиться на plt.style.use('fast') и увеличить figsize для оптимизации",
              "correct_position": 1
            }
          ]
        },
        {
          "theme": "Временные ряды и расчет статистических метрик в pandas (datetime индексы, rolling windows, describe, corr)",
          "questions": [
            {
              "level": "Junior",
              "question": "Какой метод pandas используется для установки колонки с датами в качестве индекса DataFrame для анализа временных рядов транзакций?",
              "correct_answer": "set_index() с параметром колонки datetime",
              "var_1": "DatetimeIndex() напрямую в конструкторе DataFrame",
              "var_2": "set_index() с параметром колонки datetime",
              "var_3": "reindex() с передачей datetime колонки",
              "var_4": "to_datetime() с параметром index=True",
              "correct_position": 2
            },
            {
              "level": "Middle",
              "question": "В чем разница между rolling(window=7).mean() и resample('7D').mean() при анализе дневных объемов транзакций в банковской системе?",
              "correct_answer": "rolling использует скользящее окно по записям, resample агрегирует по временным периодам",
              "var_1": "resample использует центрированное окно, rolling выравнивает по правому краю периода",
              "var_2": "rolling агрегирует по календарным неделям, resample использует окно из семи последних значений",
              "var_3": "rolling вычисляет кумулятивное среднее, resample выполняет простое среднее по периодам",
              "var_4": "rolling использует скользящее окно по записям, resample агрегирует по временным периодам",
              "correct_position": 4
            },
            {
              "level": "Senior",
              "question": "При расчете rolling корреляции между объемом транзакций и числом активных абонентов за 30 дней получаете NaN для первых строк. Как обработать это для дашборда руководству банка?",
              "correct_answer": "Использовать параметр min_periods в rolling для минимального количества наблюдений или fillna",
              "var_1": "Использовать параметр min_periods в rolling для минимального количества наблюдений или fillna",
              "var_2": "Использовать dropna для удаления строк с NaN перед визуализацией на дашборде",
              "var_3": "Заменить rolling на expanding для расчета корреляции с накопительным окном от начала",
              "var_4": "Применить interpolate с методом linear для заполнения пропусков в начале временного ряда",
              "correct_position": 1
            }
          ]
        }
      ]
    }
  ]
}